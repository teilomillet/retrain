# sepa-amplify: SEPA Amplification — push execution entropy away from mean
#
# Two amplification variants:
#   amp   — raw amplification (negatives flow into GTPO, which clamps weights)
#   amp_c — clamped amplification (entropies floored at 0, purely soft)
#
# 3 conditions x 3 seeds x 100 steps = 9 runs (sequential)
# Compare against previous SEPA pooling baselines at:
#   logs/campaign_20260222_085036
#
# Run (sequential, all 9):
#   retrain campaigns/sepa-amplify.toml
#
# Run (parallel, skip baseline — Tinker supports concurrent sessions):
#   retrain campaigns/sepa-amplify-amp.toml &
#   retrain campaigns/sepa-amplify-amp-c.toml &

[campaign]
seeds = [42, 101, 202]
max_steps = 100

[[campaign.conditions]]
advantage_mode = "grpo"
transform_mode = "none"

[[campaign.conditions]]
advantage_mode = "maxrl"
transform_mode = "gtpo_sepa_amp"

[[campaign.conditions]]
advantage_mode = "maxrl"
transform_mode = "gtpo_sepa_amp_c"

# --- base training config ---

[backend]
backend = "tinker"

[model]
model = "Qwen/Qwen3-4B-Instruct-2507"
lora_rank = 128

[training]
batch_size = 8
group_size = 16
max_tokens = 2048
temperature = 0.7
lr = 4e-5
save_every = 20

[planning]
detector = "semantic"

[sepa]
steps = 100
schedule = "linear"
delay_steps = 5

[squeeze]
min_variance_retention = 0.95

[logging]
wandb_project = "sepa-amplify"
