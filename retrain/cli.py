"""Single entry point for retrain.

Usage:
    retrain                  # loads retrain.toml from cwd
    retrain config.toml      # single training run
    retrain campaign.toml    # campaign (if TOML has [campaign] section)
    retrain backends         # list backend capabilities/schema metadata
    retrain init             # generate a starter retrain.toml
    retrain doctor           # check installed dependencies for all components
    retrain migrate-config config.toml   # migrate legacy backend keys
    retrain man              # human/agent-friendly manual
    retrain --seed 42 --lr 1e-4   # override config values from CLI

A TOML with a [campaign] section runs multiple conditions × seeds.
A TOML without it runs a single training job. Same command either way.
"""

from __future__ import annotations

import difflib
import json
import os
import re
import sys
import tomllib
from pathlib import Path


_STARTER_TOML = """\
# retrain configuration — generated by `retrain init`
# Docs: docs/configuration.md

[model]
model = "Qwen/Qwen3-4B-Instruct-2507"
lora_rank = 32

[algorithm]
advantage_mode = "maxrl"     # grpo | maxrl | my_module.my_advantage
transform_mode = "gtpo_sepa" # none | gtpo | ... | my_module.make_transform_spec

[training]
seed = -1                    # -1 = no seed
max_steps = 100              # conservative default for first run
batch_size = 4               # conservative default for first run
group_size = 16
max_tokens = 10240
temperature = 0.7
lr = 4e-5
save_every = 20

[backend]
backend = "local"
adapter_path = "adapters/my_run"

[logging]
log_dir = "logs/train"
# wandb_project = ""         # uncomment to enable wandb
"""


_QUICKSTART_TOML = """\
# retrain quickstart — 20-step smoke test
# Generated by `retrain init --template quickstart`

[model]
model = "Qwen/Qwen3-4B-Instruct-2507"
lora_rank = 32

[algorithm]
advantage_mode = "grpo"
transform_mode = "none"

[training]
seed = -1
max_steps = 20
batch_size = 2
group_size = 8
max_tokens = 1024            # smoke-test profile (non-default)
temperature = 0.7
lr = 4e-5
save_every = 0               # no checkpoints for a quick test

[backend]
backend = "local"
adapter_path = "adapters/quickstart"

[logging]
log_dir = "logs/quickstart"
"""

_EXPERIMENT_TOML = """\
# retrain experiment — reproducible 500-step training run
# Generated by `retrain init --template experiment`

[model]
model = "Qwen/Qwen3-4B-Instruct-2507"
lora_rank = 32

[algorithm]
advantage_mode = "maxrl"
transform_mode = "gtpo_sepa"

[training]
seed = 42
max_steps = 500
batch_size = 8
group_size = 16
max_tokens = 10240
temperature = 0.7
lr = 4e-5
save_every = 50

[sepa]
steps = 500
schedule = "linear"
delay_steps = 50
correct_rate_gate = 0.1

[backend]
backend = "local"
adapter_path = "adapters/experiment"

[logging]
log_dir = "logs/experiment"
wandb_project = ""           # set your project name to enable wandb
"""

_CAMPAIGN_TOML = """\
# retrain campaign — sweep across conditions and seeds
# Generated by `retrain init --template campaign`

[campaign]
seeds = [42, 101, 202, 303]
max_steps = 200

[[campaign.conditions]]
advantage_mode = "grpo"
transform_mode = "none"

[[campaign.conditions]]
advantage_mode = "maxrl"
transform_mode = "gtpo_sepa"

# Base config shared by all runs
[model]
model = "Qwen/Qwen3-4B-Instruct-2507"
lora_rank = 32

[training]
batch_size = 8
group_size = 16
max_tokens = 10240
temperature = 0.7
lr = 4e-5

[backend]
backend = "local"
adapter_path = "adapters/campaign"

[logging]
log_dir = "logs/campaign"
# wandb_project = ""         # uncomment to enable wandb
"""

# name -> (content, filename)
_INIT_TEMPLATES: dict[str, tuple[str, str]] = {
    "default": (_STARTER_TOML, "retrain.toml"),
    "quickstart": (_QUICKSTART_TOML, "retrain.toml"),
    "experiment": (_EXPERIMENT_TOML, "retrain.toml"),
    "campaign": (_CAMPAIGN_TOML, "campaign.toml"),
}


_TOPIC_TO_SECTION = {
    "quickstart": "QUICKSTART",
    "environment": "ENVIRONMENT",
    "environments": "ENVIRONMENT",
    "troubleshooting": "TROUBLESHOOTING",
    "commands": "COMMANDS",
    "options": "OPTIONS",
    "configuration": "CONFIGURATION",
    "campaign": "CAMPAIGN MODE",
    "squeeze": "SQUEEZE MODE",
    "inference": "INFERENCE ENGINES",
    "validation": "VALIDATION",
    "diff": "DIFF MODE",
    "logging": "LOGGING",
    "examples": "EXAMPLES",
    "advantages": "ADVANTAGE PIPELINE",
    "metrics": "METRICS GUIDE",
    "capacity": "CAPACITY PLANNING",
    "capacity-planning": "CAPACITY PLANNING",
    "architecture": "ARCHITECTURE",
    "files": "FILES",
    "plugins": "PLUGINS",
    "glossary": "GLOSSARY",
}

_AUTO_BLOCK_NAMES = (
    "COMMANDS",
    "OPTIONS",
    "QUICKSTART",
    "ENVIRONMENT",
)


def _print_top_help(cli_name: str) -> None:
    """Print concise top-level help with strong manual discoverability."""
    print(f"{cli_name} — TOML-first RLVR trainer")
    print()
    print("Usage:")
    print(f"  {cli_name} [config.toml] [--flag value ...]")
    print(f"  {cli_name} backends [--json]")
    print(f"  {cli_name} doctor")
    print(
        f"  {cli_name} migrate-config <config.toml> "
        "[--check|--write|--output PATH] [--backup] [--stdin|--stdout] [--json]"
    )
    print(f"  {cli_name} init [--template NAME] [--list] [--interactive]")
    print(
        f"  {cli_name} init-plugin --kind KIND --name NAME "
        "[--output-dir DIR] [--with-test]"
    )
    print(f"  {cli_name} plugins [--json] [config.toml]")
    print(f"  {cli_name} status [logdir] [--json]")
    print(f"  {cli_name} explain [config.toml] [--json]")
    print(f"  {cli_name} diff <run_a> <run_b> [--json]")
    print(f"  {cli_name} trace [config.toml] [--json]")
    print(f"  {cli_name} man")
    print()
    print("Manual:")
    print(f"  {cli_name} man")
    print(f"  {cli_name} man --topic quickstart")
    print(f"  {cli_name} man --path")
    print(f"  {cli_name} man --sync")
    print(f"  {cli_name} man --check")
    print()
    print("Tip: read docs/configuration.md for full TOML reference.")


def _resolve_cli_name() -> str:
    """Best-effort CLI binary name for help text."""
    name = Path(sys.argv[0]).name.strip()
    if (
        not name
        or name in {"python", "python3", "pytest", "py.test"}
        or name.endswith(".py")
        or "pytest" in name
    ):
        return "retrain"
    return name


def _manual_path() -> Path:
    """Location of the editable bundled manual file."""
    return Path(__file__).with_name("retrain.man")


def _load_manual_text(cli_name: str) -> str:
    """Load manual text and substitute runtime command name."""
    path = _manual_path()
    if not path.is_file():
        # Backward-compat fallback for older installs.
        legacy = Path(__file__).with_name("vauban.man")
        if legacy.is_file():
            path = legacy
    if path.is_file():
        text = path.read_text()
    else:
        text = (
            "RETRAIN(1)\n\nNAME\n"
            "    retrain - manual file missing (reinstall package)\n"
        )
    return text.replace("{{CLI}}", cli_name).rstrip() + "\n"


def _is_manual_heading(line: str) -> bool:
    s = line.strip()
    if not s or s != line:
        return False
    allowed = set("ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 _-()")
    return all(ch in allowed for ch in s) and any(ch.isalpha() for ch in s)


def _extract_manual_section(manual_text: str, heading: str) -> str | None:
    """Extract one heading section from manual text."""
    wanted = heading.strip().upper()
    lines = manual_text.splitlines()

    start = None
    for i, line in enumerate(lines):
        if _is_manual_heading(line) and line.strip().upper() == wanted:
            start = i
            break
    if start is None:
        return None

    end = len(lines)
    for i in range(start + 1, len(lines)):
        if _is_manual_heading(lines[i]) and lines[i].strip().upper() != wanted:
            end = i
            break
    return "\n".join(lines[start:end]).rstrip() + "\n"


def _render_commands_block(cli_name: str) -> list[str]:
    return [
        f"    {cli_name} [config.toml]",
        "        Run one training job.",
        "        If config.toml is omitted, uses ./retrain.toml when present.",
        "",
        f"    {cli_name} campaign.toml",
        "        Runs campaign mode when [campaign] exists in TOML.",
        "        Generates conditions x seeds matrix of training runs.",
        "        Set parallel = true in [campaign] for concurrent execution.",
        "        max_workers limits concurrent subprocess count.",
        "",
        f"    {cli_name} squeeze.toml",
        "        Runs squeeze mode when [squeeze] exists in TOML.",
        "        Analyzes LoRA rank via SVD and optionally compresses.",
        "",
        f"    {cli_name} doctor",
        "        Checks optional dependencies for configured components.",
        "",
        f"    {cli_name} backends [--json]",
        "        Prints backend metadata (capabilities, deps, option schema).",
        "        --json            machine-readable JSON output.",
        "",
        f"    {cli_name} migrate-config <config.toml> [--check|--write|--output PATH] [--backup] [--stdin|--stdout] [--json]",
        "        Migrates legacy [backend] prime_rl_* keys into [backend.options].",
        "        Default mode previews a unified diff and does not write files.",
        "        --check           exits 1 when migration is required.",
        "        --write           writes migration in place.",
        "        --output PATH     writes migrated config to a new path.",
        "        --backup          writes <config>.bak before in-place write.",
        "        --stdin           reads source TOML from stdin.",
        "        --stdout          prints migrated TOML instead of a diff.",
        "        --json            machine-readable report.",
        "",
        f"    {cli_name} init [--template NAME] [--list] [--interactive]",
        "        Writes a starter config in the current directory.",
        "        Templates: default, quickstart, experiment, campaign.",
        "        --template NAME   selects a template (default: default).",
        "        --list            shows available templates.",
        "        --interactive/-i  guided setup with prompts.",
        "",
        f"    {cli_name} init-plugin --kind KIND --name NAME [--output-dir DIR] [--with-test]",
        "        Scaffolds a student-friendly plugin module.",
        "        Kinds: transform, advantage, algorithm, reward, planning, data,",
        "               backend, inference, backpressure.",
        "        --with-test       also generates a smoke test template.",
        "",
        f"    {cli_name} plugins [--json] [config.toml]",
        "        Lists built-ins + discovered plugin modules.",
        "        If config.toml is provided, uses its [plugins] search_paths.",
        "",
        f"    {cli_name} status [logdir] [--json]",
        "        Scans log directories for run and campaign status.",
        "        Defaults to ./logs when no path is given.",
        "        --json            machine-readable JSON output.",
        "",
        f"    {cli_name} explain [config.toml] [--json]",
        "        Dry-run preview: shows what a config would do.",
        "        Works for single runs, campaigns, and squeeze configs.",
        "        --json            machine-readable JSON output.",
        "",
        f"    {cli_name} diff <run_a> <run_b> [--json]",
        "        Compares metrics between two training runs.",
        f"    {cli_name} diff <campaign_dir> <cond_a> <cond_b> [--json]",
        "        Compares two conditions in a campaign (averaged across seeds).",
        "        --json            machine-readable JSON output.",
        "",
        f"    {cli_name} trace [config.toml] [--json]",
        "        Pre-flight validation: build flow, trace with synthetic data.",
        "        Catches incompatible modes, missing data, and unsupported",
        "        uncertainty kinds before committing GPU time.",
        "        --json            machine-readable JSON output.",
        "",
        f"    {cli_name} man",
        "        Shows this manual.",
        "        --topic <name>    prints one section.",
        "        --path            prints the manual file path.",
        "        --list-topics     lists supported topic names.",
        "        --sync            refreshes auto-generated manual blocks.",
        "        --check           exits non-zero if auto blocks are stale.",
        "        --json            outputs JSON (full manual or single topic).",
    ]


def _render_options_block() -> list[str]:
    from retrain.config import _CLI_FLAG_MAP

    # Keep only canonical flags for readability; skip alias here and add below.
    canonical = sorted(k for k in _CLI_FLAG_MAP if k != "--resume")
    lines = [
        "    TrainConfig fields are exposed as --kebab-case CLI flags.",
        "    Flags override TOML values.",
        "",
        "    Common examples:",
        "        retrain config.toml --seed 42 --max-steps 50",
        "        retrain config.toml --lr 1e-4 --batch-size 16",
        "        retrain config.toml --advantage-mode grpo",
        "        retrain config.toml --advantage-param scale=2.0 --transform-param cap=0.1",
        "        retrain config.toml --inference-engine vllm --inference-url http://localhost:8000",
        "        retrain config.toml --backend prime_rl --backend-opt transport=zmq --backend-opt zmq_port=7777",
        "",
        "    All flags (sorted):",
    ]
    for flag in canonical:
        lines.append(f"        {flag}")

    lines.extend(
        [
            "",
            "    Special flags:",
            "        --backend-opt K=V    backend-specific option override (repeatable).",
            "        --algorithm-param K=V algorithm plugin params (repeatable).",
            "        --advantage-param K=V advantage plugin params (repeatable).",
            "        --transform-param K=V transform plugin params (repeatable).",
            "        --resume VALUE    alias for --resume-from VALUE",
            "",
            "    Unknown flags produce an error with close-match suggestions.",
        ]
    )
    return lines


def _render_quickstart_block(cli_name: str) -> list[str]:
    return [
        "    cp retrain.toml my_run.toml",
        f"    {cli_name} my_run.toml",
        f"    {cli_name} my_run.toml --seed 42 --max-steps 50",
    ]


def _render_environment_block(cli_name: str) -> list[str]:
    from retrain.verifiers_bridge import _FALLBACK_TRAINING_ENVS

    lines = [
        f"    {cli_name} uses verifiers environments for RLVR training data.",
        "    Set [environment].provider = \"verifiers\" and specify a Hub ID.",
        "",
        "    Trainable verifiers examples:",
    ]
    for env_id in _FALLBACK_TRAINING_ENVS:
        lines.append(f"        {env_id}")
    lines.extend(
        [
            "",
            "    Caveat:",
            "        Some hub environments are eval-only and do not expose training",
            f"        datasets. In that case {cli_name} fails fast with actionable guidance.",
        ]
    )
    return lines


def _replace_auto_block(text: str, name: str, rendered_lines: list[str]) -> str:
    start = f"<<AUTO:{name}>>"
    end = f"<<END:AUTO:{name}>>"
    lines = text.splitlines()
    out: list[str] = []
    i = 0
    replaced = False
    while i < len(lines):
        line = lines[i]
        if line.strip() == start:
            replaced = True
            out.append(line)
            out.extend(rendered_lines)
            i += 1
            while i < len(lines) and lines[i].strip() != end:
                i += 1
            if i >= len(lines):
                raise ValueError(f"Missing block end marker: {end}")
            out.append(lines[i])
            i += 1
            continue
        out.append(line)
        i += 1

    if not replaced:
        raise ValueError(f"Missing block markers for {name}: {start} ... {end}")

    return "\n".join(out).rstrip() + "\n"


def _sync_manual_file(cli_name: str) -> tuple[Path, bool]:
    """Refresh auto-generated blocks in the editable manual."""
    path = _manual_path()
    original = path.read_text() if path.is_file() else _load_manual_text(cli_name)

    updated = original
    rendered = {
        "COMMANDS": _render_commands_block(cli_name),
        "OPTIONS": _render_options_block(),
        "QUICKSTART": _render_quickstart_block(cli_name),
        "ENVIRONMENT": _render_environment_block(cli_name),
    }
    for name in _AUTO_BLOCK_NAMES:
        updated = _replace_auto_block(updated, name, rendered[name])

    changed = updated != original
    if changed:
        path.write_text(updated)
    return path, changed


def _check_manual_file(cli_name: str) -> tuple[Path, bool]:
    """Check whether auto-generated manual blocks are up to date."""
    path = _manual_path()
    original = path.read_text() if path.is_file() else _load_manual_text(cli_name)

    updated = original
    rendered = {
        "COMMANDS": _render_commands_block(cli_name),
        "OPTIONS": _render_options_block(),
        "QUICKSTART": _render_quickstart_block(cli_name),
        "ENVIRONMENT": _render_environment_block(cli_name),
    }
    for name in _AUTO_BLOCK_NAMES:
        updated = _replace_auto_block(updated, name, rendered[name])
    return path, updated == original


def _run_man(args: list[str]) -> None:
    """Print manual text (or JSON view) from bundled editable file."""
    fmt = "text"
    topic: str | None = None
    show_path = False
    list_topics = False
    sync = False
    check = False
    i = 0
    while i < len(args):
        arg = args[i]
        if arg == "--json":
            fmt = "json"
        elif arg == "--path":
            show_path = True
        elif arg == "--list-topics":
            list_topics = True
        elif arg == "--sync":
            sync = True
        elif arg == "--check":
            check = True
        elif arg in ("--format", "-f"):
            i += 1
            if i >= len(args):
                print("Flag --format requires a value: text|json", file=sys.stderr)
                sys.exit(1)
            fmt = args[i]
        elif arg.startswith("--format="):
            fmt = arg.split("=", 1)[1]
        elif arg in ("--topic", "-t"):
            i += 1
            if i >= len(args):
                print("Flag --topic requires a value.", file=sys.stderr)
                sys.exit(1)
            topic = args[i]
        elif arg.startswith("--topic="):
            topic = arg.split("=", 1)[1]
        else:
            print(f"Unknown man flag: {arg}", file=sys.stderr)
            sys.exit(1)
        i += 1

    if fmt not in ("text", "json", "troff", "html"):
        print(f"Unsupported format '{fmt}'. Use text|json|troff|html.", file=sys.stderr)
        sys.exit(1)

    cli_name = _resolve_cli_name()
    if sync and check:
        print("Flags --sync and --check cannot be used together.", file=sys.stderr)
        sys.exit(1)

    manual_path = _manual_path()
    if sync:
        try:
            manual_path, changed = _sync_manual_file(cli_name)
        except ValueError as exc:
            print(f"Manual sync failed: {exc}", file=sys.stderr)
            sys.exit(1)
        status = "updated" if changed else "already up to date"
        print(f"{manual_path} ({status})")
        return

    if check:
        try:
            manual_path, up_to_date = _check_manual_file(cli_name)
        except ValueError as exc:
            print(f"Manual check failed: {exc}", file=sys.stderr)
            sys.exit(1)
        if up_to_date:
            print(f"{manual_path} (up to date)")
            return
        print(
            f"{manual_path} (out of date). Run: {cli_name} man --sync",
            file=sys.stderr,
        )
        sys.exit(1)

    manual_text = _load_manual_text(cli_name)

    if show_path:
        print(str(manual_path))
        return

    if list_topics:
        for name in sorted(_TOPIC_TO_SECTION):
            print(name)
        return

    section_name: str | None = None
    section_text: str | None = None
    if topic is not None:
        section_name = _TOPIC_TO_SECTION.get(topic.lower(), topic.upper())
        section_text = _extract_manual_section(manual_text, section_name)
        if section_text is None:
            print(
                f"Unknown topic '{topic}'. Available: {sorted(_TOPIC_TO_SECTION)}",
                file=sys.stderr,
            )
            sys.exit(1)

    if fmt in ("troff", "html"):
        from retrain.man_export import parse_manual, to_html, to_troff

        source = section_text if section_text is not None else manual_text
        sections = parse_manual(source)
        formatter = to_troff if fmt == "troff" else to_html
        print(formatter(sections).rstrip())
        return

    if fmt == "json":
        if section_text is None:
            payload = {
                "tool": cli_name,
                "path": str(manual_path),
                "topics": sorted(_TOPIC_TO_SECTION),
                "manual": manual_text,
            }
        else:
            payload = {
                "tool": cli_name,
                "path": str(manual_path),
                "topic": topic,
                "section": section_name,
                "content": section_text,
            }
        print(json.dumps(payload, indent=2))
        return

    if section_text is None:
        print(manual_text.rstrip())
    else:
        print(section_text.rstrip())


def _customize_toml(
    content: str,
    max_steps: int | None = None,
    seed: int | None = None,
    wandb_project: str | None = None,
) -> str:
    """Apply customizations to a TOML template string via regex."""
    if max_steps is not None:
        content = re.sub(r"^(max_steps\s*=\s*)\d+", rf"\g<1>{max_steps}", content, flags=re.MULTILINE)
    if seed is not None:
        content = re.sub(r"^(seed\s*=\s*)-?\d+", rf"\g<1>{seed}", content, flags=re.MULTILINE)
    if wandb_project is not None:
        if wandb_project:
            # Uncomment and set
            content = re.sub(
                r"^#\s*wandb_project\s*=.*$",
                f'wandb_project = "{wandb_project}"',
                content,
                flags=re.MULTILINE,
            )
            # Replace already-uncommented line
            content = re.sub(
                r'^wandb_project\s*=\s*"[^"]*"',
                f'wandb_project = "{wandb_project}"',
                content,
                flags=re.MULTILINE,
            )
        # Empty string: leave as-is (commented or empty)
    return content


_INTERACTIVE_GOALS: dict[str, tuple[str, int]] = {
    "1": ("quickstart", 20),
    "2": ("experiment", 500),
    "3": ("campaign", 200),
}


def _run_init_interactive(cli_name: str) -> None:
    """Interactively build a retrain config file."""
    if not sys.stdin.isatty():
        print("Interactive init requires a terminal (TTY).", file=sys.stderr)
        sys.exit(1)

    print(f"{cli_name} init — interactive setup\n")
    print("What would you like to do?")
    print("  1) quickstart  — 20-step smoke test")
    print("  2) experiment  — reproducible training run")
    print("  3) campaign    — sweep across conditions and seeds")
    choice = input("\nChoice [1]: ").strip() or "1"
    if choice not in _INTERACTIVE_GOALS:
        print(f"Invalid choice '{choice}'. Using quickstart.", file=sys.stderr)
        choice = "1"

    goal_name, default_steps = _INTERACTIVE_GOALS[choice]

    # Steps
    steps_input = input(f"Training steps [{default_steps}]: ").strip()
    if steps_input:
        try:
            max_steps = int(steps_input)
        except ValueError:
            print(f"Not a number, using default ({default_steps}).", file=sys.stderr)
            max_steps = default_steps
    else:
        max_steps = default_steps

    # Seed
    seed_input = input("Reproducible seed [42]: ").strip()
    if seed_input:
        try:
            seed = int(seed_input)
        except ValueError:
            print("Not a number, using default (42).", file=sys.stderr)
            seed = 42
    else:
        seed = 42

    # Wandb
    wandb_project = input("Wandb project name (empty to skip): ").strip()

    content, filename = _INIT_TEMPLATES[goal_name]
    content = _customize_toml(content, max_steps=max_steps, seed=seed, wandb_project=wandb_project or None)

    dest = Path(filename)
    if dest.exists():
        print(f"{filename} already exists — refusing to overwrite.")
        sys.exit(1)
    dest.write_text(content)
    print(f"\nCreated {filename} (template: {goal_name})")
    print(f"Edit it, then run: {cli_name}")


def _run_init(args: list[str] | None = None, cli_name: str | None = None) -> None:
    """Generate a starter config file in the current directory."""
    if not cli_name:
        cli_name = _resolve_cli_name()
    args = args or []

    template_name = "default"
    list_templates = False
    interactive = False
    i = 0
    while i < len(args):
        arg = args[i]
        if arg in ("--interactive", "-i"):
            interactive = True
        elif arg in ("--list", "-l"):
            list_templates = True
        elif arg in ("--template", "-t"):
            i += 1
            if i >= len(args):
                print("Flag --template requires a value.", file=sys.stderr)
                sys.exit(1)
            template_name = args[i]
        elif arg.startswith("--template="):
            template_name = arg.split("=", 1)[1]
        else:
            print(f"Unknown init flag: {arg}", file=sys.stderr)
            sys.exit(1)
        i += 1

    if list_templates:
        print("Available templates:")
        for name, (_, filename) in sorted(_INIT_TEMPLATES.items()):
            print(f"  {name:12s} -> {filename}")
        return

    if interactive:
        _run_init_interactive(cli_name)
        return

    if template_name not in _INIT_TEMPLATES:
        print(
            f"Unknown template '{template_name}'. "
            f"Available: {sorted(_INIT_TEMPLATES)}",
            file=sys.stderr,
        )
        sys.exit(1)

    content, filename = _INIT_TEMPLATES[template_name]
    dest = Path(filename)
    if dest.exists():
        print(f"{filename} already exists — refusing to overwrite.")
        sys.exit(1)
    dest.write_text(content)
    print(f"Created {filename} (template: {template_name})")
    print(f"Edit it, then run: {cli_name}")
    print(f"Need guidance? Run: {cli_name} man")


_PLUGIN_KINDS = {
    "transform",
    "advantage",
    "algorithm",
    "reward",
    "planning",
    "data",
    "backend",
    "inference",
    "backpressure",
}


def _sanitize_identifier(name: str) -> str:
    cleaned = re.sub(r"[^A-Za-z0-9_]+", "_", name.strip())
    cleaned = re.sub(r"_+", "_", cleaned).strip("_")
    if not cleaned:
        return "my_plugin"
    if cleaned[0].isdigit():
        cleaned = f"plugin_{cleaned}"
    return cleaned


def _plugin_template(kind: str, fn_name: str) -> tuple[str, str]:
    """Return (module_content, toml_snippet) for plugin scaffolding."""
    if kind == "transform":
        return (
            (
                "from retrain import TransformOutput\n\n"
                f"def {fn_name}(ctx):\n"
                "    \"\"\"ctx contains episode_advantages/logprobs/planning masks/params.\"\"\"\n"
                "    token_advs = []\n"
                "    for i, logprobs in enumerate(ctx.logprobs_G):\n"
                "        adv = ctx.episode_advantages[i]\n"
                "        token_advs.append([adv for _ in logprobs])\n"
                "    return TransformOutput(\n"
                "        token_advs=token_advs,\n"
                "        has_stats=False,\n"
                "        needs_planning=False,\n"
                "        uses_sepa_controller=False,\n"
                "    )\n"
            ),
            (
                "[algorithm]\n"
                f'transform_mode = "plugins.{fn_name}.{fn_name}"\n'
                "\n[algorithm.transform_params]\n"
                "scale = 1.0\n"
            ),
        )
    if kind == "advantage":
        return (
            (
                f"def {fn_name}(rewards, params=None):\n"
                "    \"\"\"Return one advantage per reward.\"\"\"\n"
                "    if not rewards:\n"
                "        return []\n"
                "    scale = float((params or {}).get('scale', 1.0))\n"
                "    mean_r = sum(rewards) / len(rewards)\n"
                "    return [scale * (r - mean_r) for r in rewards]\n"
            ),
            (
                "[algorithm]\n"
                f'advantage_mode = "plugins.{fn_name}.{fn_name}"\n'
                "\n[algorithm.advantage_params]\n"
                "scale = 2.0\n"
            ),
        )
    if kind == "algorithm":
        return (
            (
                "from retrain import AlgorithmOutput\n\n"
                f"def {fn_name}(ctx):\n"
                "    \"\"\"Full algorithm hook: return token-level advantages directly.\"\"\"\n"
                "    token_advs = []\n"
                "    for rewards_idx, logprobs in enumerate(ctx.logprobs_G):\n"
                "        reward = ctx.rewards_G[rewards_idx]\n"
                "        token_advs.append([reward for _ in logprobs])\n"
                "    return AlgorithmOutput(token_advs=token_advs, has_stats=False)\n"
            ),
            (
                "[algorithm]\n"
                f'algorithm_mode = "plugins.{fn_name}.{fn_name}"\n'
                "\n[algorithm.params]\n"
                "alpha = 0.1\n"
            ),
        )
    if kind == "reward":
        return (
            (
                f"class {fn_name.title().replace('_', '')}Reward:\n"
                "    def score(self, response: str, reference: str) -> float:\n"
                "        return float(response.strip() == reference.strip())\n\n"
                f"def {fn_name}(config):\n"
                f"    return {fn_name.title().replace('_', '')}Reward()\n"
            ),
            (
                "[reward]\n"
                'type = "custom"\n'
                f'custom_module = "plugins.{fn_name}"\n'
                f'custom_function = "{fn_name}"\n'
            ),
        )

    generic = (
        f"def {fn_name}(config):\n"
        f"    raise NotImplementedError(\"Implement {kind} plugin contract here.\")\n"
    )
    return (
        generic,
        f"# Use dotted plugin path: plugins.{fn_name}.{fn_name}\n",
    )


def _run_init_plugin(args: list[str], cli_name: str | None = None) -> None:
    """Scaffold a plugin module for students."""
    if not cli_name:
        cli_name = _resolve_cli_name()
    kind = ""
    name = ""
    output_dir = "plugins"
    with_test = False

    i = 0
    while i < len(args):
        arg = args[i]
        if arg == "--with-test":
            with_test = True
        elif arg in ("--kind", "-k"):
            i += 1
            if i >= len(args):
                print("Flag --kind requires a value.", file=sys.stderr)
                sys.exit(1)
            kind = args[i].strip().lower()
        elif arg.startswith("--kind="):
            kind = arg.split("=", 1)[1].strip().lower()
        elif arg in ("--name", "-n"):
            i += 1
            if i >= len(args):
                print("Flag --name requires a value.", file=sys.stderr)
                sys.exit(1)
            name = args[i].strip()
        elif arg.startswith("--name="):
            name = arg.split("=", 1)[1].strip()
        elif arg in ("--output-dir", "-o"):
            i += 1
            if i >= len(args):
                print("Flag --output-dir requires a value.", file=sys.stderr)
                sys.exit(1)
            output_dir = args[i].strip()
        elif arg.startswith("--output-dir="):
            output_dir = arg.split("=", 1)[1].strip()
        else:
            print(f"Unknown init-plugin flag: {arg}", file=sys.stderr)
            sys.exit(1)
        i += 1

    if kind not in _PLUGIN_KINDS:
        print(
            f"Invalid --kind '{kind}'. "
            f"Choose one of: {sorted(_PLUGIN_KINDS)}",
            file=sys.stderr,
        )
        sys.exit(1)
    if not name:
        print("Flag --name is required.", file=sys.stderr)
        sys.exit(1)

    module_name = _sanitize_identifier(name)
    module_content, snippet = _plugin_template(kind, module_name)
    out_dir = Path(output_dir)
    plugin_path = out_dir / f"{module_name}.py"
    test_path = Path("tests") / f"test_{module_name}_plugin.py"

    if plugin_path.exists():
        print(f"{plugin_path} already exists — refusing to overwrite.")
        sys.exit(1)
    if with_test and test_path.exists():
        print(f"{test_path} already exists — refusing to overwrite.")
        sys.exit(1)

    out_dir.mkdir(parents=True, exist_ok=True)
    plugin_path.write_text(module_content)
    print(f"Created {plugin_path}")

    if with_test:
        test_path.parent.mkdir(parents=True, exist_ok=True)
        test_path.write_text(
            "import importlib\n\n"
            f"def test_{module_name}_importable():\n"
            f"    mod = importlib.import_module('plugins.{module_name}')\n"
            f"    assert hasattr(mod, '{module_name}')\n"
        )
        print(f"Created {test_path}")

    print("\nTOML snippet:")
    print(snippet.rstrip())
    print(f"\nRun it with: {cli_name} retrain.toml")


def _run_plugins(args: list[str]) -> None:
    """List built-in and discovered plugins."""
    from retrain.advantages import (
        get_builtin_algorithm_modes,
        get_builtin_advantage_modes,
        get_builtin_transform_modes,
    )
    from retrain.config import TrainConfig, load_config
    from retrain.plugin_resolver import discover_plugin_modules, get_plugin_runtime
    from retrain.registry import get_registry

    fmt = "text"
    config_path: str | None = None
    for arg in args:
        if arg == "--json":
            fmt = "json"
        elif arg.startswith("--"):
            print(f"Unknown plugins flag: {arg}", file=sys.stderr)
            sys.exit(1)
        else:
            config_path = arg

    if config_path:
        cfg = load_config(config_path)
    else:
        cfg = TrainConfig()
    runtime = get_plugin_runtime()
    discovered = discover_plugin_modules(cfg.plugins_search_paths)

    import importlib

    discovered_entries: list[dict[str, str]] = []
    for module_name in discovered:
        try:
            importlib.import_module(module_name)
            status = "ok"
        except Exception as exc:
            status = f"error: {exc.__class__.__name__}"
        discovered_entries.append({"module": module_name, "status": status})

    payload: dict[str, object] = {
        "runtime": {
            "search_paths": list(runtime.search_paths),
            "strict": runtime.strict,
        },
        "builtins": {
            "algorithm_mode": get_builtin_algorithm_modes(),
            "advantage_mode": get_builtin_advantage_modes(),
            "transform_mode": get_builtin_transform_modes(),
            "backend": get_registry("backend").builtin_names,
            "inference_engine": get_registry("inference_engine").builtin_names,
            "reward": get_registry("reward").builtin_names,
            "planning_detector": get_registry("planning_detector").builtin_names,
            "data_source": get_registry("data_source").builtin_names,
            "backpressure": get_registry("backpressure").builtin_names,
        },
        "discovered": discovered_entries,
    }

    if fmt == "json":
        print(json.dumps(payload, indent=2))
        return

    print("Plugin runtime:")
    print(f"  search_paths: {', '.join(runtime.search_paths)}")
    print(f"  strict      : {runtime.strict}")
    print("\nBuilt-ins:")
    for key, values in payload["builtins"].items():  # type: ignore[index]
        print(f"  {key}: {', '.join(values)}")
    print("\nDiscovered modules:")
    if discovered_entries:
        for item in discovered_entries:
            print(f"  {item['module']}: {item['status']}")
    else:
        print("  (none)")


def _load_dotenv() -> None:
    """Load .env file if present. Sets vars into os.environ."""
    env_path = Path(".env")
    if not env_path.exists():
        return
    for line in env_path.read_text().splitlines():
        line = line.strip()
        if not line or line.startswith("#"):
            continue
        eq = line.find("=")
        if eq == -1:
            continue
        key = line[:eq].strip()
        val = line[eq + 1 :].strip()
        if len(val) >= 2 and val[0] == val[-1] and val[0] in ('"', "'"):
            val = val[1:-1]
        os.environ[key] = val
    print("Loaded .env")


def _is_squeeze(path: str) -> bool:
    """Check if a TOML file has a [squeeze] section."""
    with open(path, "rb") as f:
        data = tomllib.load(f)
    return "squeeze" in data


def _is_campaign(path: str) -> bool:
    """Check if a TOML file has a [campaign] section."""
    with open(path, "rb") as f:
        data = tomllib.load(f)
    return "campaign" in data


def _resolve_backend_capability_payload(
    backend_name: str,
    backend_options: dict[str, object] | None = None,
) -> dict[str, object]:
    from retrain.backend_definitions import (
        backend_capability_source,
        resolve_backend_capabilities,
    )

    caps = resolve_backend_capabilities(backend_name, backend_options or {})
    return {
        "backend": backend_name,
        "source": backend_capability_source(backend_name, backend_options or {}),
        "reports_sync_loss": caps.reports_sync_loss,
        "preserves_token_advantages": caps.preserves_token_advantages,
        "supports_checkpoint_resume": caps.supports_checkpoint_resume,
        "resume_runtime_dependent": caps.resume_runtime_dependent,
    }


def _format_backend_capability_summary(capabilities: dict[str, object]) -> str:
    return (
        f"source={capabilities['source']}, "
        f"reports_sync_loss={capabilities['reports_sync_loss']}, "
        f"preserves_token_advantages={capabilities['preserves_token_advantages']}, "
        f"supports_checkpoint_resume={capabilities['supports_checkpoint_resume']}, "
        f"resume_runtime_dependent={capabilities['resume_runtime_dependent']}"
    )


def _run_backends(args: list[str]) -> None:
    """Print backend metadata catalog."""
    from retrain.backend_definitions import describe_backends_catalog

    fmt = "text"
    for arg in args:
        if arg == "--json":
            fmt = "json"
        elif arg.startswith("--"):
            print(f"Unknown backends flag: {arg}", file=sys.stderr)
            sys.exit(1)
        else:
            print(f"Unexpected argument for backends: {arg}", file=sys.stderr)
            sys.exit(1)

    payload = describe_backends_catalog()
    if fmt == "json":
        print(json.dumps(payload, indent=2))
        return

    print("Built-in backends:")
    for backend_item in payload["builtins"]:
        name = backend_item["name"]
        dep = backend_item["dependency"]
        caps = backend_item["capabilities"]
        print(f"  {name}")
        print(f"    dependency: {dep['import']} ({dep['hint']})")
        print(
            "    capabilities: "
            f"reports_sync_loss={caps['reports_sync_loss']}, "
            f"preserves_token_advantages={caps['preserves_token_advantages']}, "
            f"supports_checkpoint_resume={caps['supports_checkpoint_resume']}, "
            f"resume_runtime_dependent={caps['resume_runtime_dependent']}"
        )
        option_schema = backend_item["option_schema"]
        if option_schema:
            print("    options:")
            for key, spec in sorted(option_schema.items()):
                choices = spec.get("choices")
                choice_text = f" choices={choices}" if choices else ""
                print(
                    f"      {key}: type={spec['type']} default={spec['default']!r}{choice_text}"
                )
        else:
            print("    options: none")

    plugin = payload["plugin"]
    print("\nPlugin metadata hooks:")
    print(f"  dotted_path_supported: {plugin['dotted_path_supported']}")
    print(f"  capability_hooks     : {', '.join(plugin['capability_hooks'])}")
    print(f"  option_schema_hooks  : {', '.join(plugin['option_schema_hooks'])}")
    print(f"  schema_format        : {plugin['option_schema_format']}")


def _run_doctor() -> None:
    """Print dependency status for all known components."""
    from retrain.backend_definitions import get_builtin_backend_definitions
    from retrain.registry import check_environment, probe_backend_runtime

    print("retrain doctor — checking component dependencies\n")
    results = check_environment(config=None)
    all_ok = True
    for name, import_name, hint, available in results:
        status = "OK" if available else "MISSING"
        if not available:
            all_ok = False
        print(f"  {name:20s} {import_name:25s} {status}")
        if not available:
            print(f"  {'':20s} -> {hint}")

    print("\nBackend capability summary:")
    for backend_name in sorted(get_builtin_backend_definitions()):
        caps = _resolve_backend_capability_payload(backend_name, {})
        print(f"  {backend_name:20s} {_format_backend_capability_summary(caps)}")
    plugin_caps = _resolve_backend_capability_payload("myplugin.CustomBackend", {})
    print(f"  {'plugin/default':20s} {_format_backend_capability_summary(plugin_caps)}")

    print("\nRuntime probes:")
    for probe in probe_backend_runtime(config=None):
        print(
            f"  {probe.backend:20s} {probe.probe:20s} "
            f"{probe.status.upper():5s} {probe.detail}"
        )

    print()
    if all_ok:
        print("All optional dependencies are installed.")
    else:
        print("Some optional dependencies are missing (see above).")


def _check_environment(config: "TrainConfig") -> None:  # noqa: F821
    """Warn if the config references components whose deps are missing."""
    from retrain.registry import check_environment

    results = check_environment(config=config)
    for name, import_name, hint, available in results:
        if not available:
            print(
                f"WARNING: component '{name}' requires '{import_name}' "
                f"which is not installed.\n  -> {hint}"
            )


def _run_status(args: list[str]) -> None:
    """Scan log directories and print run/campaign status."""
    import time as _time

    from retrain.status import (
        format_campaign,
        format_run,
        scan_all,
    )

    fmt = "text"
    root = "logs"
    show_all = False
    watch = False
    positional: list[str] = []
    for arg in args:
        if arg == "--json":
            fmt = "json"
        elif arg == "--all":
            show_all = True
        elif arg == "--active":
            show_all = False
        elif arg == "--watch":
            watch = True
        elif arg.startswith("--"):
            print(f"Unknown status flag: {arg}", file=sys.stderr)
            sys.exit(1)
        else:
            positional.append(arg)

    if positional:
        root = positional[0]

    root_path = Path(root)
    if not root_path.is_dir():
        print(f"No log directory found: {root}")
        sys.exit(1)

    _active_statuses = {"running", "partial"}

    while True:
        runs, campaigns = scan_all(root_path)

        if not show_all:
            campaigns = [c for c in campaigns if c.status in _active_statuses]

        if fmt == "json":
            payload = {
                "root": str(root_path),
                "runs": [r.to_dict() for r in runs],
                "campaigns": [c.to_dict() for c in campaigns],
            }
            print(json.dumps(payload, indent=2))
            if not watch:
                return
        else:
            if not runs and not campaigns:
                if show_all:
                    print(f"No runs or campaigns found in {root}")
                else:
                    print(f"No active campaigns in {root}  (use --all to see everything)")
            else:
                if campaigns:
                    for camp in campaigns:
                        print(format_campaign(camp))
                        print()

                if runs:
                    print("Standalone runs:")
                    for run in runs:
                        print(format_run(run))

        if not watch:
            return

        try:
            _time.sleep(5)
            # Clear screen for refresh
            print("\033[2J\033[H", end="")
        except KeyboardInterrupt:
            return


def _explain_single(config_path: str | None, fmt: str) -> None:
    """Explain what a single training run would do."""
    import warnings

    from retrain.config import load_config
    from retrain.registry import check_environment

    with warnings.catch_warnings(record=True) as caught:
        warnings.simplefilter("always")
        config = load_config(config_path)

    condition = (
        config.algorithm_mode
        if config.algorithm_mode
        else f"{config.advantage_mode}+{config.transform_mode}"
    )
    datums_per_step = config.batch_size * config.group_size
    total_datums = datums_per_step * config.max_steps
    lora_alpha = config.lora_alpha if config.lora_alpha else config.lora_rank * 2
    data_info = config.data_source
    if config.environment_provider:
        data_info = f"{config.environment_provider}:{config.environment_id}"
    backend_capabilities = _resolve_backend_capability_payload(
        config.backend,
        config.backend_options,
    )

    info: dict = {
        "mode": "single",
        "config": config_path or "retrain.toml",
        "model": config.model,
        "backend": config.backend,
        "backend_options": dict(config.backend_options),
        "backend_capabilities": backend_capabilities,
        "condition": condition,
        "algorithm_mode": config.algorithm_mode,
        "advantage_mode": config.advantage_mode,
        "transform_mode": config.transform_mode,
        "max_steps": config.max_steps,
        "batch_size": config.batch_size,
        "group_size": config.group_size,
        "datums_per_step": datums_per_step,
        "total_datums": total_datums,
        "max_tokens": config.max_tokens,
        "temperature": config.temperature,
        "lr": config.lr,
        "seed": config.seed,
        "lora_rank": config.lora_rank,
        "lora_alpha": lora_alpha,
        "data": data_info,
        "reward_type": config.reward_type,
        "log_dir": config.log_dir,
        "adapter_path": config.adapter_path,
        "wandb_project": config.wandb_project or "(disabled)",
        "warnings": [str(w.message) for w in caught],
    }

    # Dependency warnings
    dep_warnings = []
    results = check_environment(config=config)
    for name, import_name, hint, available in results:
        if not available:
            dep_warnings.append(f"{name} requires {import_name} ({hint})")
    if dep_warnings:
        info["dep_warnings"] = dep_warnings

    if fmt == "json":
        print(json.dumps(info, indent=2))
        return

    print(f"retrain explain — dry-run preview")
    print(f"  config        : {info['config']}")
    print(f"  model         : {config.model}")
    print(f"  backend       : {config.backend}")
    print(f"  backend caps  : {_format_backend_capability_summary(backend_capabilities)}")
    if not backend_capabilities["reports_sync_loss"]:
        print("  note          : loss is reported as placeholder by backend design")
    print(f"  condition     : {condition}")
    print(f"  steps         : {config.max_steps}")
    print(f"  batch_size    : {config.batch_size}")
    print(f"  group_size    : {config.group_size}")
    print(f"  datums/step   : {datums_per_step}")
    print(f"  total datums  : {total_datums}")
    print(f"  max_tokens    : {config.max_tokens}")
    print(f"  temperature   : {config.temperature}")
    print(f"  lr            : {config.lr}")
    print(f"  seed          : {config.seed}")
    print(f"  lora          : rank={config.lora_rank} alpha={lora_alpha}")
    print(f"  data          : {data_info}")
    print(f"  reward        : {config.reward_type}")
    print(f"  log_dir       : {config.log_dir}")
    print(f"  adapter_path  : {config.adapter_path}")
    print(f"  wandb         : {info['wandb_project']}")
    if caught:
        print("\nWarnings:")
        for w in caught:
            print(f"  - {w.message}")
    if dep_warnings:
        print("\nMissing dependencies:")
        for dw in dep_warnings:
            print(f"  - {dw}")


def _explain_campaign(config_path: str, fmt: str) -> None:
    """Explain what a campaign would do."""
    from retrain.campaign import DEFAULT_SEEDS, _parse_campaign_conditions

    with open(config_path, "rb") as f:
        data = tomllib.load(f)

    campaign = data.get("campaign", {})
    seeds = campaign.get("seeds", DEFAULT_SEEDS)
    max_steps = campaign.get("max_steps", 500)
    raw_conditions = campaign.get("conditions", None)
    conditions = _parse_campaign_conditions(raw_conditions, config_path)
    condition_labels = [c.label for c in conditions]
    total_runs = len(conditions) * len(seeds)
    backend_sec = data.get("backend", {})
    backend_name = "local"
    backend_options: dict[str, object] = {}
    if isinstance(backend_sec, dict):
        backend_name = str(backend_sec.get("backend", "local") or "local")
        raw_options = backend_sec.get("options", {})
        if isinstance(raw_options, dict):
            backend_options = dict(raw_options)
    backend_capabilities = _resolve_backend_capability_payload(
        backend_name,
        backend_options,
    )

    info = {
        "mode": "campaign",
        "config": config_path,
        "backend": backend_name,
        "backend_capabilities": backend_capabilities,
        "conditions": condition_labels,
        "seeds": seeds,
        "max_steps": max_steps,
        "total_runs": total_runs,
    }

    if fmt == "json":
        print(json.dumps(info, indent=2))
        return

    print(f"retrain explain — campaign dry-run preview")
    print(f"  config        : {config_path}")
    print(f"  backend       : {backend_name}")
    print(f"  backend caps  : {_format_backend_capability_summary(backend_capabilities)}")
    print(f"  conditions    : {', '.join(condition_labels)}")
    print(f"  seeds         : {seeds}")
    print(f"  max_steps     : {max_steps}")
    print(f"  total runs    : {total_runs}")


def _explain_squeeze(config_path: str, fmt: str) -> None:
    """Explain what a squeeze run would do."""
    from retrain.config import load_squeeze_config

    cfg = load_squeeze_config(config_path)

    info = {
        "mode": "squeeze",
        "config": config_path,
        "adapter_path": cfg.adapter_path,
        "source_rank": cfg.source_rank,
        "min_variance_retention": cfg.min_variance_retention,
    }
    if cfg.output_path:
        info["output_path"] = cfg.output_path
    if cfg.compress_to > 0:
        info["compress_to"] = cfg.compress_to

    if fmt == "json":
        print(json.dumps(info, indent=2))
        return

    print(f"retrain explain — squeeze dry-run preview")
    print(f"  config                : {config_path}")
    print(f"  adapter_path          : {cfg.adapter_path}")
    print(f"  source_rank           : {cfg.source_rank}")
    print(f"  min_variance_retention: {cfg.min_variance_retention}")
    if cfg.output_path:
        print(f"  output_path           : {cfg.output_path}")
    if cfg.compress_to > 0:
        print(f"  compress_to           : {cfg.compress_to}")


def _run_diff(args: list[str]) -> None:
    """Compare two runs or campaign conditions."""
    from retrain.diff import diff_conditions, diff_runs, format_diff

    fmt = "text"
    positional: list[str] = []
    for arg in args:
        if arg == "--json":
            fmt = "json"
        elif arg.startswith("--"):
            print(f"Unknown diff flag: {arg}", file=sys.stderr)
            sys.exit(1)
        else:
            positional.append(arg)

    if len(positional) == 2:
        dir_a, dir_b = Path(positional[0]), Path(positional[1])
        try:
            result = diff_runs(dir_a, dir_b)
        except FileNotFoundError as exc:
            print(str(exc), file=sys.stderr)
            sys.exit(1)
    elif len(positional) == 3:
        campaign_dir = Path(positional[0])
        cond_a, cond_b = positional[1], positional[2]
        try:
            result = diff_conditions(campaign_dir, cond_a, cond_b)
        except FileNotFoundError as exc:
            print(str(exc), file=sys.stderr)
            sys.exit(1)
    else:
        print("Usage:", file=sys.stderr)
        print("  retrain diff <run_a> <run_b>", file=sys.stderr)
        print("  retrain diff <campaign_dir> <cond_a> <cond_b>", file=sys.stderr)
        sys.exit(1)

    if fmt == "json":
        from dataclasses import asdict

        print(json.dumps(asdict(result), indent=2))
    else:
        print(format_diff(result))


def _run_migrate_config(args: list[str]) -> None:
    """Migrate legacy backend config keys to [backend.options] format."""
    from retrain.config import migrate_legacy_backend_keys_toml_text

    check_only = False
    write_in_place = False
    backup = False
    stdin_mode = False
    stdout_mode = False
    json_mode = False
    output_path: str | None = None
    positional: list[str] = []

    i = 0
    while i < len(args):
        arg = args[i]
        if arg == "--check":
            check_only = True
        elif arg == "--write":
            write_in_place = True
        elif arg == "--backup":
            backup = True
        elif arg == "--stdin":
            stdin_mode = True
        elif arg == "--stdout":
            stdout_mode = True
        elif arg == "--json":
            json_mode = True
        elif arg in ("--output", "-o"):
            i += 1
            if i >= len(args):
                print("Flag --output requires a path.", file=sys.stderr)
                sys.exit(1)
            output_path = args[i]
        elif arg.startswith("--output="):
            output_path = arg.split("=", 1)[1]
        elif arg.startswith("--"):
            print(f"Unknown migrate-config flag: {arg}", file=sys.stderr)
            sys.exit(1)
        else:
            positional.append(arg)
        i += 1

    if stdin_mode and positional:
        print("Use either a config path or --stdin, not both.", file=sys.stderr)
        sys.exit(1)
    if not stdin_mode and len(positional) != 1:
        print(
            "Usage: retrain migrate-config <config.toml> "
            "[--check|--write|--output PATH] [--backup] [--stdin|--stdout] [--json]",
            file=sys.stderr,
        )
        sys.exit(1)
    if check_only and (write_in_place or output_path or stdout_mode or backup):
        print(
            "Flag --check cannot be combined with --write, --output, --stdout, or --backup.",
            file=sys.stderr,
        )
        sys.exit(1)
    if stdin_mode and write_in_place:
        print("Flag --write requires a file path input (cannot be used with --stdin).", file=sys.stderr)
        sys.exit(1)
    if write_in_place and output_path:
        print("Use either --write or --output, not both.", file=sys.stderr)
        sys.exit(1)
    if stdout_mode and (write_in_place or output_path):
        print("Flag --stdout cannot be combined with --write or --output.", file=sys.stderr)
        sys.exit(1)
    if backup and not write_in_place:
        print("Flag --backup can only be used with --write.", file=sys.stderr)
        sys.exit(1)

    config_path: Path | None = None
    source_label = "<stdin>"
    if stdin_mode:
        original_text = sys.stdin.read()
        if not original_text:
            print("No TOML content received on stdin.", file=sys.stderr)
            sys.exit(1)
    else:
        config_path = Path(positional[0])
        if not config_path.is_file():
            print(f"File not found: {config_path}", file=sys.stderr)
            sys.exit(1)
        source_label = str(config_path)
        original_text = config_path.read_text()

    try:
        migrated = migrate_legacy_backend_keys_toml_text(original_text)
    except tomllib.TOMLDecodeError as exc:
        print(f"Invalid TOML in {source_label}: {exc}", file=sys.stderr)
        sys.exit(1)

    needs_migration = bool(migrated.legacy_keys)
    diff_text = "\n".join(
        difflib.unified_diff(
            original_text.splitlines(),
            migrated.output_text.splitlines(),
            fromfile=source_label,
            tofile=f"{source_label}.migrated",
            lineterm="",
        )
    )

    mode = "preview"
    if check_only:
        mode = "check"
    elif write_in_place:
        mode = "write"
    elif output_path:
        mode = "output"
    elif stdout_mode:
        mode = "stdout"

    payload: dict[str, object] = {
        "config": source_label,
        "mode": mode,
        "needs_migration": needs_migration,
        "changed": migrated.changed,
        "legacy_keys": list(migrated.legacy_keys),
        "merged_backend_options": migrated.merged_backend_options,
        "diff": diff_text,
        "written": False,
        "output_path": None,
        "backup_path": None,
    }

    if check_only:
        if json_mode:
            print(json.dumps(payload, indent=2))
        elif needs_migration:
            keys = ", ".join(migrated.legacy_keys)
            print(f"Migration required in {source_label} (legacy keys: {keys}).")
        else:
            print(f"No migration needed: {source_label}")
        if needs_migration:
            sys.exit(1)
        return

    if write_in_place:
        assert config_path is not None
        if backup:
            backup_path = Path(str(config_path) + ".bak")
            backup_path.write_text(original_text)
            payload["backup_path"] = str(backup_path)
        config_path.write_text(migrated.output_text)
        payload["written"] = True
        payload["output_path"] = str(config_path)
    elif output_path:
        out_path = Path(output_path)
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out_path.write_text(migrated.output_text)
        payload["written"] = True
        payload["output_path"] = str(out_path)

    if json_mode:
        print(json.dumps(payload, indent=2))
        return

    if stdout_mode:
        print(migrated.output_text, end="")
        return

    if payload["written"]:
        if needs_migration:
            print(f"Migrated config written to {payload['output_path']}")
        else:
            print(f"No migration required. Wrote unchanged config to {payload['output_path']}")
        if payload["backup_path"]:
            print(f"Backup written to {payload['backup_path']}")
        return

    if needs_migration:
        print(diff_text)
    else:
        print(f"No migration needed: {source_label}")


def _run_explain(args: list[str]) -> None:
    """Dry-run: show what a config would do without running it."""
    fmt = "text"
    config_path: str | None = None
    for arg in args:
        if arg == "--json":
            fmt = "json"
        elif arg.startswith("--"):
            print(f"Unknown explain flag: {arg}", file=sys.stderr)
            sys.exit(1)
        else:
            config_path = arg

    # Resolve config path
    if config_path is None:
        if Path("retrain.toml").is_file():
            config_path = "retrain.toml"
        else:
            print("No config file specified and no retrain.toml in cwd.")
            sys.exit(1)

    if not Path(config_path).is_file():
        print(f"File not found: {config_path}")
        sys.exit(1)

    # Route by config type
    if _is_campaign(config_path):
        _explain_campaign(config_path, fmt)
    elif _is_squeeze(config_path):
        _explain_squeeze(config_path, fmt)
    else:
        _explain_single(config_path, fmt)


def _run_trace(args: list[str]) -> None:
    """Pre-flight validation: build flow, trace with synthetic data."""
    from retrain.config import load_config
    from retrain.flow import build_flow

    config_path: str | None = None
    json_mode = False
    for arg in args:
        if arg == "--json":
            json_mode = True
        elif not arg.startswith("--") and config_path is None:
            config_path = arg
        else:
            print(f"Unknown argument: {arg}", file=sys.stderr)
            sys.exit(1)

    if config_path is not None and not Path(config_path).is_file():
        print(f"File not found: {config_path}", file=sys.stderr)
        sys.exit(1)

    try:
        config = load_config(config_path)
    except (ValueError, FileNotFoundError) as exc:
        print(f"Config error: {exc}", file=sys.stderr)
        sys.exit(1)

    flow = build_flow(config, gpu=False)
    result = flow.trace()

    if json_mode:
        payload = {
            "ok": result.ok,
            "probe_cases_run": result.probe_cases_run,
            "probe_cases_passed": result.probe_cases_passed,
            "issues": [
                {
                    "severity": i.severity,
                    "category": i.category,
                    "message": i.message,
                }
                for i in result.issues
            ],
            "flow": {
                "condition_label": flow.condition_label,
                "backend": config.backend,
                "backend_capability_source": flow.backend_capability_source,
                "needs_planning": flow.needs_planning,
                "uses_sepa_controller": flow.uses_sepa_controller,
                "preserves_token_advantages": flow.backend_capabilities.preserves_token_advantages,
            },
        }
        print(json.dumps(payload, indent=2))
    else:
        print(f"Condition: {flow.condition_label}")
        print(f"Backend:   {config.backend} (source: {flow.backend_capability_source})")
        print(
            f"Probes:    {result.probe_cases_passed}/{result.probe_cases_run} passed"
        )
        if result.issues:
            print()
            for issue in result.issues:
                tag = "[ERROR]" if issue.severity == "error" else "[WARN]"
                print(f"  {tag} [{issue.category}] {issue.message}")
        print()
        if result.ok:
            print("PASS")
        else:
            print("FAIL")

    sys.exit(0 if result.ok else 1)


def main() -> None:
    """Single entry point: retrain config.toml"""
    _load_dotenv()

    args = sys.argv[1:]
    cli_name = _resolve_cli_name()

    if args and args[0] in ("-h", "--help", "help"):
        _print_top_help(cli_name)
        sys.exit(0)

    if args and args[0] in ("man", "manual"):
        _run_man(args[1:])
        sys.exit(0)

    if args and args[0] == "backends":
        _run_backends(args[1:])
        sys.exit(0)

    if args and args[0] == "doctor":
        _run_doctor()
        sys.exit(0)

    if args and args[0] == "migrate-config":
        _run_migrate_config(args[1:])
        sys.exit(0)

    if args and args[0] == "init":
        _run_init(args=args[1:], cli_name=cli_name)
        sys.exit(0)

    if args and args[0] == "init-plugin":
        _run_init_plugin(args=args[1:], cli_name=cli_name)
        sys.exit(0)

    if args and args[0] == "plugins":
        _run_plugins(args[1:])
        sys.exit(0)

    if args and args[0] == "status":
        _run_status(args[1:])
        sys.exit(0)

    if args and args[0] == "explain":
        _run_explain(args[1:])
        sys.exit(0)

    if args and args[0] == "diff":
        _run_diff(args[1:])
        sys.exit(0)

    if args and args[0] == "trace":
        _run_trace(args[1:])
        sys.exit(0)

    # Parse CLI overrides
    from retrain.config import parse_cli_overrides

    config_path, overrides = parse_cli_overrides(args)

    # Resolve config path
    if config_path is None:
        if Path("retrain.toml").is_file():
            config_path = "retrain.toml"
        elif not overrides:
            if sys.stdin.isatty():
                answer = input("No retrain.toml found. Create one now? [Y/n]: ").strip().lower()
                if answer in ("", "y", "yes"):
                    _run_init(cli_name=cli_name)
                    sys.exit(0)
            print("No retrain.toml found. Create one with:")
            print(f"  {cli_name} init")
            print("Or pass a path:")
            print(f"  {cli_name} path/to/config.toml")
            print("Manual:")
            print(f"  {cli_name} man")
            sys.exit(1)
        # else: overrides-only mode, use defaults

    if config_path is not None and not Path(config_path).is_file():
        print(f"File not found: {config_path}")
        sys.exit(1)

    # Route: campaign | squeeze | single run
    # Campaign/squeeze only when a TOML file is provided (CLI overrides don't apply)
    if config_path is not None and _is_campaign(config_path):
        from retrain.campaign import run_campaign
        run_campaign(config_path)
    elif config_path is not None and _is_squeeze(config_path):
        from retrain.squeeze import run_squeeze
        run_squeeze(config_path)
    else:
        from retrain.config import load_config
        from retrain.trainer import train
        config = load_config(config_path, overrides=overrides)
        _check_environment(config)
        train(config)


if __name__ == "__main__":
    main()
